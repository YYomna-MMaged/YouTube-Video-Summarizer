{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:17:55.837504Z",
     "iopub.status.busy": "2025-08-24T15:17:55.837218Z",
     "iopub.status.idle": "2025-08-24T15:19:13.925003Z",
     "shell.execute_reply": "2025-08-24T15:19:13.924104Z",
     "shell.execute_reply.started": "2025-08-24T15:17:55.837479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install youtube-transcript-api\n",
    "# !pip install transformers torch\n",
    "# !pip install langcodes langdetect\n",
    "# !pip install arabert\n",
    "# !pip install --upgrade transformers\n",
    "# !pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:19:13.962520Z",
     "iopub.status.busy": "2025-08-24T15:19:13.962269Z",
     "iopub.status.idle": "2025-08-24T15:19:14.112144Z",
     "shell.execute_reply": "2025-08-24T15:19:14.111609Z",
     "shell.execute_reply.started": "2025-08-24T15:19:13.962499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import regex as re #help in extracting video id pattern from url\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled #handling transcript fetching cases\n",
    "from urllib.parse import urlparse, parse_qs, unquote #dealing with url\n",
    "\n",
    "pattern = re.compile(r\"(?:v=|/)([0-9A-Za-z_-]{11})(?:[&?\\/]|$)\")\n",
    "\"\"\"\n",
    "    (?:v=|/) and (?:[&?\\/]|$ --> non-capturing groups\n",
    "    ([0-9A-Za-z_-]{11}) --> capturing group\n",
    "\"\"\"\n",
    "\n",
    "def extract_id(url : str) -> str:\n",
    "    parsed = urlparse(url) #break url into (scheme, netloc, path, params, query, fragment)\n",
    "    qs = parse_qs(parsed.query) #get url id (help more with attribution_link)\n",
    "\n",
    "    #check if it`s an attribution link and deal with it if\n",
    "    if parsed.path.startswith(\"/attribution_link\") and \"u\" in qs: \n",
    "        nested_url = unquote(qs[\"u\"][0]) #unquote -> decode encoded special chars\n",
    "        \n",
    "        if nested_url.startswith(\"/\"):\n",
    "            re_url = \"https://www.youtube.com\" + nested_url\n",
    "        return extract_id(re_url)\n",
    "\n",
    "    #dealing with normal url patterns\n",
    "    video_id = pattern.search(url) #search pattern in url\n",
    "    if not video_id:\n",
    "        raise ValueError(f\"Can not extract id form: {url}\")\n",
    "    return video_id.group(1) #group(1) -> return first capturing group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:19:14.113050Z",
     "iopub.status.busy": "2025-08-24T15:19:14.112833Z",
     "iopub.status.idle": "2025-08-24T15:19:14.118528Z",
     "shell.execute_reply": "2025-08-24T15:19:14.117839Z",
     "shell.execute_reply.started": "2025-08-24T15:19:14.113024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_transcript(video_id : str, preferred_languages = (\"ar\", \"en\")) -> str:\n",
    "    try:\n",
    "        api = YouTubeTranscriptApi()\n",
    "        transcript_list = api.list(video_id) #return all avalibale transcripts\n",
    "\n",
    "        for language in preferred_languages: #loop over preferred languages\n",
    "            try:\n",
    "                transcript = transcript_list.find_transcript([language]) \n",
    "                fetched = transcript.fetch()\n",
    "                return \"\\n\".join(snippet.text for snippet in fetched if snippet.text.strip())\n",
    "            except NoTranscriptFound: #if no transcript with this language\n",
    "                continue\n",
    "\n",
    "        #if no transcript with preferred languages is available, take the transcript with the original/first language\n",
    "        transcript = next(iter(transcript_list)) \n",
    "        fetched = transcript.fetch()\n",
    "        return \"\\n\".join(part.text for part in fetched if part.text.strip())\n",
    "\n",
    "    except TranscriptsDisabled: #if the video does not have a transcript\n",
    "        return \"NO Transcript at this video\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:19:14.119473Z",
     "iopub.status.busy": "2025-08-24T15:19:14.119256Z",
     "iopub.status.idle": "2025-08-24T15:19:14.134008Z",
     "shell.execute_reply": "2025-08-24T15:19:14.133355Z",
     "shell.execute_reply.started": "2025-08-24T15:19:14.119435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stop = re.compile(r\"[\\p{P}\\p{Zs}\\n\\t]\") # help in finding the split position\n",
    "# def get_chunks(text: str, chunk_size = 700, overlap = 50) -> list[str]:\n",
    "\n",
    "def get_chunks(text: str, chunk_size = 500) -> list[str]:\n",
    "    chunks = []\n",
    "\n",
    "    while len(text) > chunk_size: #loop over transcript untill it ends\n",
    "        match = list(stop.finditer(text[:chunk_size])) #create list of all \"stop\" characters in selected part\n",
    "\n",
    "        if match:\n",
    "            split_at = match[-1].end() #split position after last match\n",
    "        else:\n",
    "            split_at = chunk_size\n",
    "\n",
    "        #overlap -> to make sure that every part will be understandable\n",
    "        # chunks.append(text[:split_at + overlap].strip())\n",
    "        # text = text[split_at - overlap:].lstrip()\n",
    "\n",
    "        chunks.append(text[:split_at].strip())\n",
    "        text = text[split_at:].lstrip()\n",
    "\n",
    "    if text:\n",
    "        chunks.append(text.strip())\n",
    "    return chunks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:19:14.134902Z",
     "iopub.status.busy": "2025-08-24T15:19:14.134697Z",
     "iopub.status.idle": "2025-08-24T15:20:00.603658Z",
     "shell.execute_reply": "2025-08-24T15:20:00.602518Z",
     "shell.execute_reply.started": "2025-08-24T15:19:14.134886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langdetect import detect\n",
    "import langcodes\n",
    "\n",
    "trans_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "trans_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:20:00.605515Z",
     "iopub.status.busy": "2025-08-24T15:20:00.604590Z",
     "iopub.status.idle": "2025-08-24T15:20:00.622846Z",
     "shell.execute_reply": "2025-08-24T15:20:00.617932Z",
     "shell.execute_reply.started": "2025-08-24T15:20:00.605483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_lang_code(text : str) -> str:\n",
    "    lang_ios_code = detect(text) #return the language ISO code\n",
    "    language = langcodes.Language.get(lang_ios_code) #create a language object from code to get language script\n",
    "    script = language.maximize().script\n",
    "\n",
    "    code = f\"{lang_ios_code}_{script}\"\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:20:00.634186Z",
     "iopub.status.busy": "2025-08-24T15:20:00.633787Z",
     "iopub.status.idle": "2025-08-24T15:20:02.083065Z",
     "shell.execute_reply": "2025-08-24T15:20:02.081837Z",
     "shell.execute_reply.started": "2025-08-24T15:20:00.634161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate(text, src_lang, tgt_lang):\n",
    "    translator = pipeline(\n",
    "        \"translation\",\n",
    "        model = trans_model,\n",
    "        tokenizer = trans_tokenizer,\n",
    "        src_lang = src_lang,\n",
    "        tgt_lang = tgt_lang,\n",
    "        device = 0\n",
    "    )\n",
    "\n",
    "    result = translator(text,  max_length = 400)\n",
    "    return result[0][\"translation_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T16:29:35.048633Z",
     "iopub.status.busy": "2025-08-24T16:29:35.048094Z",
     "iopub.status.idle": "2025-08-24T16:29:35.058634Z",
     "shell.execute_reply": "2025-08-24T16:29:35.057877Z",
     "shell.execute_reply.started": "2025-08-24T16:29:35.048608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    #delete anything but numbers, characters, and some symbolsÿ≤\n",
    "    text = re.sub(r\"[^\\p{L}\\p{N}\\s.!?,:;]\", \" \", text)\n",
    "    \n",
    "    #remove repeted spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    #remove duplicate words and phrases, both adjacent and non-adjacent.\n",
    "    #remove adjacent duplication (quickly).\n",
    "    for phrase_length in range(20, 0, -1):\n",
    "        if phrase_length == 1:\n",
    "            text = re.sub(r'\\b(\\w+)(\\s+\\1\\b)+', r'\\1', text)\n",
    "        else:\n",
    "            pattern = r'\\b((?:\\w+\\s+){' + str(phrase_length-1) + r'}\\w+)(\\s+\\1\\b)+'\n",
    "            text = re.sub(pattern, r'\\1', text)\n",
    "    \n",
    "    #remove non-contiguous repetition of common phrases.\n",
    "    def remove_non_adjacent_duplicates(text):\n",
    "        words = text.split()\n",
    "        if len(words) < 4:\n",
    "            return text\n",
    "        \n",
    "        phrase_counts = {} #search for repeated phrases (2-6 words)\n",
    "        \n",
    "        #count the phrases\n",
    "        for length in range(2, 7):  # 2 to 6 words\n",
    "            for i in range(len(words) - length + 1):\n",
    "                phrase = tuple(words[i:i+length])\n",
    "                if phrase not in phrase_counts:\n",
    "                    phrase_counts[phrase] = []\n",
    "                phrase_counts[phrase].append(i)\n",
    "        \n",
    "        #find phrases that are repeated more than once\n",
    "        duplicates_to_remove = []\n",
    "        for phrase, positions in phrase_counts.items():\n",
    "            if len(positions) > 1 and len(phrase) >= 2:\n",
    "                #keep the first position and delete the rest\n",
    "                duplicates_to_remove.extend(positions[1:])\n",
    "        \n",
    "        #arrange the positions for deletion from last to first\n",
    "        duplicates_to_remove.sort(reverse=True)\n",
    "        \n",
    "        #delete duplicate phrases\n",
    "        result_words = words.copy()\n",
    "        for pos in duplicates_to_remove:\n",
    "            #find the length of the phrase in this position\n",
    "            for phrase, positions in phrase_counts.items():\n",
    "                if pos in positions[1:]:  #if the position is duplicated\n",
    "                    phrase_len = len(phrase)\n",
    "                    #remove phrase\n",
    "                    for _ in range(phrase_len):\n",
    "                        if pos < len(result_words):\n",
    "                            result_words.pop(pos)\n",
    "                    break\n",
    "        \n",
    "        return ' '.join(result_words)\n",
    "    \n",
    "    text = remove_non_adjacent_duplicates(text)\n",
    "    \n",
    "    #clean spaces again after removing duplicates.\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    #remove duplicate sentences\n",
    "    #divide by different punctuation marks\n",
    "    sentences = re.split(r'[.!?\\n]+', text)\n",
    "    seen = set()\n",
    "    unique_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        #clean the sentence from extra spaces and marks at the beginning and end\n",
    "        sentence = re.sub(r'^[^\\w]+|[^\\w]+$', '', sentence).strip()\n",
    "        \n",
    "        if sentence and len(sentence) > 2:  #ignore very short sentences.\n",
    "            #compare sentences after converting them to lowercase to avoid duplicate sensitivity to letters.\n",
    "            sentence_lower = sentence.lower()\n",
    "            if sentence_lower not in seen:\n",
    "                seen.add(sentence_lower)\n",
    "                unique_sentences.append(sentence)\n",
    "    \n",
    "    #connect sentences with appropriate punctuation.\n",
    "    if unique_sentences:\n",
    "        result = \". \".join(unique_sentences)\n",
    "        #add a dot at the end if it doesn't exist.\n",
    "        if not result.endswith(('.', '!', '?')):\n",
    "            result += \".\"\n",
    "        return result\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T15:20:02.889233Z",
     "iopub.status.busy": "2025-08-24T15:20:02.888975Z",
     "iopub.status.idle": "2025-08-24T15:20:23.137289Z",
     "shell.execute_reply": "2025-08-24T15:20:23.136491Z",
     "shell.execute_reply.started": "2025-08-24T15:20:02.889209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T16:29:40.072775Z",
     "iopub.status.busy": "2025-08-24T16:29:40.072542Z",
     "iopub.status.idle": "2025-08-24T16:30:12.276702Z",
     "shell.execute_reply": "2025-08-24T16:30:12.275924Z",
     "shell.execute_reply.started": "2025-08-24T16:29:40.072759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Your max_length is set to 130, but your input_length is only 103. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n",
      "Your max_length is set to 130, but your input_length is only 106. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=53)\n",
      "Your max_length is set to 130, but your input_length is only 85. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      "Your max_length is set to 130, but your input_length is only 115. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\n",
      "Your max_length is set to 130, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 130, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 130, but your input_length is only 112. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n",
      "Your max_length is set to 130, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 130, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, I'm not ready because I don't know what you're saying - What are we going to talk about? - Yes - Yes - Good. It's OK. Victoria, how are you? - Good. Nothing new. - Nothing new? - And you? - Me? I'm doing well because now we're recording a new video and this is a new format. - Yes - We've never recorded such a video. so I think it will be interesting and useful for the students.\n",
      "_________________________________________________\n",
      "How long have you been studying Russian? - How long have you been studying Russian? - I think five years. Summer? - Years - Years - Five years? - Yes. No. four. - Four years? - I don't know. Four years. - Four or five. - Yes Yes Yes. I forgot. - What do you... How do you learn? - It's okay, but. How do you do it? How do you learn Russian? What do you do when you learn Russian?\n",
      "_________________________________________________\n",
      "Usually watch BeFluent on YouTube. because I have you at home. with me. at home, yes. at home with me. you have me you can talk to me at home. yes yes. and if you have a question you can ask me. yes, of course, I understand. but I watched a lot of Russian TV series maybe. no, sometimes netflix BeFluent Class and what kind. what TV shows do you watch in Russian a lot. I don't know the Russian title. name? name. yes, I know English. you know one series, the name of one. in Russian you know one.\n",
      "_________________________________________________\n",
      "Of them. one series. Method? Method and more. And Malyshariki? Malyshariki and more. Kitchen. Kitchen, I forgot. My favorite. favorite? favorite yes. Yes Yes Yes. Well, I see, what do you think you need to study now. very fast. Again. What are you thinking now. what do you need to study? The words? A conversation?\n",
      "_________________________________________________\n",
      "I understand, I understand. I need to hear. Yes. Better. but also I think you need to learn new words because you can understand well. but if you don't know the word then you think I have bad hearing but you just don't know the word. that's all. It's necessary to learn new words and also develop your listening too. both words and listening Okay? I understand. Understood? Yes OK. Hard. Well, yeah, no Russian, learning Russian is very difficult because now you are in Russia. you need to.\n",
      "_________________________________________________\n",
      "to talk to people on the street at home with me, in the store, and so on. and therefore you need to know a lot of words, you must not know a lot of words yet and therefore it is very difficult for you, it is difficult for you. but when I speak. for ours, no. with our family. Yes, a family. fine. yes because you. you know you can make mistakes. and it's okay because they understand you. you know them you're not nervous. remember nervous? nervous. yes. you're nervous. i\n",
      "_________________________________________________\n",
      "Yes, of course I agree. because when we live. Lives? We live. we live in America when I speak Russian badly because. they are because a little Russian people there. I have no practice yes practice and a lot of Russian. friends friends friends friends in America but here it's okay I have to speak Russian. Yes, I understand well, but a couple more questions are not about the Russian language.\n",
      "_________________________________________________\n",
      "What? other questions are not about the Russian language. what are your plans for this week? plans here plans for this week. a week... a week. forgot the week. Monday Tuesday Wednesday Thursday Friday ... usually. for this week today I may be. I want for the weekend, for the weekend, for the weekend I will do sports, sports. with my friend, friend. but, I study Russian, of course, and maybe. see mine. friend is another friend another friend and yes. all I think about is my friend.\n",
      "_________________________________________________\n",
      "Nothing interesting is nothing new, but I know that you'll have a modeling shoot on Monday. Monday Monday modeling you'll be a model I forgot. On Monday. I forgot, on the next one, I don't want to talk about what because. it's not here it's later. yes yes yes it's then and I'm *trying to say \"nervous\". I'm nervous. *another attempt at the word \"nervous\"* yes, almost.\n",
      "_________________________________________________\n",
      "about, we are talking because I, when I think very slowly. you speak slowly. yes. good. thank you excellent teacher. you are welcome. bye.\n",
      "_________________________________________________\n",
      "10\n",
      "Victoria is preparing to record a new video for her students. She says it will be in a new format and will be 'interesting and useful for the students' She says she is doing well as she is preparing for the new video to be recorded. But she admits she is not ready to talk about it yet.\n",
      "_________________________________________________\n",
      "How long have you been studying Russian? - I think five years. - Four or five. - Yes Yes Yes. I forgot. How do you learn? - It's okay, but. how do you do it? How do we learn Russian? What do we do when we learn it?\n",
      "_________________________________________________\n",
      " usually watch BeFluent on YouTube. because I have you at home. with me. at home, yes. you have me you can talk to me at home with you. yes yes. and if you have a question you can ask me. yes, of course, I understand. but I watched a lot of Russian TV series maybe. no, sometimes netflix beFluent Class and what kind. of TV shows do you watch in Russian a lot.\n",
      "_________________________________________________\n",
      "My favorite? favorite yes. Yes Yes Yes. Method? Method and more. And Malyshariki? MalysHariki and more, I forgot. Kitchen. Of them. One series. What are you thinking now. what do you need to study? The words? A conversation?\n",
      "_________________________________________________\n",
      "Learn new words because you can understand well. but if you don't know the word then you think I have bad hearing. that's all. It's necessary to learn new words and also develop your listening too. both words and listening Okay? I understand. Understood? Yes OK.\n",
      "_________________________________________________\n",
      "\"You need to know a lot of words. to talk to people on the street at home with me, in the store, and so on. and therefore it is very difficult for you, it is difficult forYou. but when I speak. for ours, no. with our family. Yes, a family. fine. yes because you. know you can make mistakes. and it's okay because they understand you\"\n",
      "_________________________________________________\n",
      "\"I have no practice yes practice and a lot of Russian,\" she says. \"I have to speak Russian. because when we live. we live in America when I speak Russian badly because. they are because a little Russian people there\" \"I understand well, but a couple more questions are not about the Russian language,\" she adds.\n",
      "_________________________________________________\n",
      "This week I will do sports, sports. with my friend, friend. I study Russian, of course, and maybe. see mine. friend is another friend another friend and yes. all I think about is my friend. What? other questions are not about the Russian language. what are your plans for this week?\n",
      "_________________________________________________\n",
      "\"I know that you'll have a modeling shoot on Monday. Monday Monday modeling you'll be a model I forgot. I forgot, on the next one, I don't want to talk about what because. it's not here it's later. yes yes yes it's then and I'm *trying to say \"nervous\". I'm nervous\"\n",
      "_________________________________________________\n",
      "We are talking. about, we are talking because I, when I think very slowly. you speak slowly. yes. good. thank you excellent teacher. you are welcome. bye. by the way, you are. welcome. to my blog. I hope to see you soon.\n",
      "_________________________________________________\n",
      "Victoria is preparing to record a new video for her students. She says it will be in format and interesting and useful for the students she is doing well as be recorded. But she admits not ready to talk about it yet. How long have you been studying Russian. I think five years. Four or five. Yes. I forgot. How do you learn. It s okay, but. how do it. we learn Russian. What do when it. usually watch BeFluent on YouTube. because I at home. with me. at home, yes. you have me you can talk to me at home with you. and if a question ask me. yes, of course, I understand. but I watched a lot of Russian TV series maybe. no, sometimes netflix beFluent Class and what kind. of TV shows watch in Russian a lot. My favorite. favorite yes. Method. Method and more. And Malyshariki. MalysHariki and more, Kitchen. Of them. One series. What are you thinking now. what need to study. The words. A conversation. Learn new words because understand well. but don t know the word then you think bad hearing. that s all. necessary to learn and also develop your listening too. both listening Okay. Understood. Yes OK. You know street store, and so on. and therefore it is very difficult for you, difficult forYou. but when I speak. for ours, no. with our family. Yes, a family. fine. yes because you. know make mistakes. and it s okay because they understand you no practice yes practice and to speak Russian. because live. we live in America speak Russian badly because. they are because a little Russian people there I understand well, but a couple more questions are not about the Russian language, she adds. This week I will do sports, sports. with my friend, friend. I study Russian, and maybe. see mine. friend is another friend and yes. all about is my friend. What. other next one, I want here later. yes then and I m trying to say nervous. nervous We are talking. about, we are talking because I, slowly. you speak slowly. good. thank you excellent teacher. you are welcome. bye. by the way, you are. welcome. to my blog. I hope to see you soon.\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\": #if uncomment this line, handel indentation\n",
    "\n",
    "# url = input(\"Enter a URL: \")\n",
    "url = 'https://www.youtube.com/watch?v=ZZF7g6aj0Zc'\n",
    "ex_id = extract_id(url)\n",
    "text = get_transcript(ex_id)\n",
    "chunks = get_chunks(text)\n",
    "\n",
    "original_language = get_lang_code(chunks[0])\n",
    "translated_chunks  = [translate(chunk, original_language, \"eng_Latn\") for chunk in chunks]\n",
    "\n",
    "summary = [summarizer(chunk, max_length = 130)[0]['summary_text'] for chunk in translated_chunks]\n",
    "\n",
    "combined_summary = \" \".join(summary)\n",
    "cleaned_final = clean_text(combined_summary)\n",
    "\n",
    "print(cleaned_final)\n",
    "print(\"_________________________________________________\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
